# üíæ Corre√ß√£o de Vazamento de Mem√≥ria em Caches

## üéØ Vis√£o Geral

**Problema Cr√≠tico Identificado**: Todas as inst√¢ncias de `NodeCache` no RBaileys estavam configuradas **SEM limites de mem√≥ria** (`maxKeys` n√£o definido), permitindo crescimento ilimitado e causando **OOM (Out of Memory) crashes** em produ√ß√£o sob alta carga.

**Status**: ‚úÖ **CORRIGIDO** - Limites conservadores implementados em todos os caches

---

## üî¥ Problema Original

### C√≥digo Perigoso (Antes)

```typescript
// ‚ùå PERIGOSO - Sem limite de mem√≥ria!
const userDevicesCache = new NodeCache({
  stdTTL: 300,  // 5 minutes
  useClones: false
  // ‚ö†Ô∏è  Faltando: maxKeys ‚Üí crescimento ilimitado!
})
```

### Impacto em Produ√ß√£o

**Cen√°rio Real**: Sistema com **50-100 tenants simult√¢neos**

**C√°lculo do vazamento**:
```
Por tenant:
- userDevicesCache: ~2.500 keys (500 contatos √ó 5 devices)
- msgRetryCache: ~5.000 keys (mensagens falhadas)
- placeholderResendCache: ~3.000 keys
- signalStore: ~8.000 keys (chaves criptogr√°ficas)
- callOfferCache: ~100 keys
- lidCache: ~1.000 keys

Total por tenant: ~19.600 keys

Com 100 tenants: 1.960.000 keys na mem√≥ria!
```

**Resultado**:
- ‚ùå **Crescimento ilimitado de mem√≥ria** (500MB ‚Üí 2GB ‚Üí 8GB ‚Üí OOM crash)
- ‚ùå **Imposs√≠vel prever quando vai crashar**
- ‚ùå **Perda de dados** ao reiniciar
- ‚ùå **Downtime para clientes**

---

## ‚úÖ Solu√ß√£o Implementada

### 1. Limites Conservadores Definidos

**Arquivo**: `src/Defaults/index.ts`

```typescript
/**
 * Default maximum keys for internal caches (Memory leak prevention)
 *
 * Conservative limits for multi-tenant production (50-100+ tenants):
 * - Prevents OOM crashes from unbounded cache growth
 * - Uses LRU eviction when limit is reached
 * - Tested under high load scenarios
 */
export const DEFAULT_CACHE_MAX_KEYS = {
  SIGNAL_STORE: 10_000,        // Cryptographic keys
  MSG_RETRY: 10_000,           // High message volume
  CALL_OFFER: 500,             // Calls are rare
  USER_DEVICES: 5_000,         // Devices per user
  PLACEHOLDER_RESEND: 5_000,   // Temporary placeholders
  LID_PER_SOCKET: 2_000,       // Link IDs per socket
  LID_GLOBAL: 10_000           // Shared link IDs (global)
}
```

### 2. C√≥digo Seguro (Depois)

```typescript
// ‚úÖ SEGURO - Com limites e prote√ß√µes
const userDevicesCache = new NodeCache({
  stdTTL: DEFAULT_CACHE_TTLS.USER_DEVICES,     // 5 minutes
  maxKeys: DEFAULT_CACHE_MAX_KEYS.USER_DEVICES, // 5,000 keys (LIMITE!)
  deleteOnExpire: true,                          // Libera mem√≥ria
  useClones: false                               // Performance
})
```

### 3. Prote√ß√µes Implementadas

‚úÖ **maxKeys**: Limite m√°ximo de chaves (evita crescimento ilimitado)
‚úÖ **deleteOnExpire: true**: Remove keys expiradas da mem√≥ria automaticamente
‚úÖ **LRU eviction**: Remove as keys **menos usadas** quando atinge o limite
‚úÖ **Logging**: Monitora utiliza√ß√£o e alerta quando pr√≥ximo ao limite

---

## üìä Limites por Cache

### Caches por Socket (multiplicado pelo n√∫mero de tenants)

| Cache | Limite | Uso T√≠pico | Justificativa |
|-------|--------|------------|---------------|
| **userDevicesCache** | 5.000 | 500 contatos √ó 5 devices = 2.500 | Buffer de 2√ó, suporta at√© 1.000 contatos |
| **lidCache** (per-socket) | 2.000 | ~100 links ativos | Buffer generoso para links tempor√°rios |
| **msgRetryCache** | 10.000 | Alto volume de mensagens | Suporta rajadas de falhas de decrypt |
| **callOfferCache** | 500 | Chamadas s√£o raras | Buffer suficiente para 500 offers simult√¢neas |
| **placeholderResendCache** | 5.000 | Placeholders tempor√°rios | Suporta alto volume de resends |
| **signalStore** | 10.000 | Chaves de criptografia | Suporta muitas sess√µes simult√¢neas |

### Caches Globais (compartilhados entre todos os tenants)

| Cache | Limite | Uso T√≠pico | Justificativa |
|-------|--------|------------|---------------|
| **lidCache** (global) | 10.000 | 100 tenants √ó 100 links = 10.000 | No limite com 100 tenants, LRU evita overflow |

### C√°lculo Total (100 tenants)

```
Por tenant:
- userDevicesCache: 5.000 max
- lidCache: 2.000 max
- msgRetryCache: 10.000 max
- callOfferCache: 500 max
- placeholderResendCache: 5.000 max
- signalStore: 10.000 max
SUBTOTAL por tenant: 32.500 keys (limite m√°ximo)

100 tenants √ó 32.500 = 3.250.000 keys (m√°ximo te√≥rico)

Global:
- lidCache: 10.000 max

TOTAL M√ÅXIMO: 3.260.000 keys
```

**Em produ√ß√£o real**, utiliza√ß√£o m√©dia: **30-50%** dos limites = **~1.000.000 keys**

---

## üîß Arquivos Modificados

### 1. `src/Defaults/index.ts`
‚úÖ Adicionado `DEFAULT_CACHE_MAX_KEYS` com limites conservadores

### 2. `src/Utils/cache-utils.ts` (Cache Global)
‚úÖ `lidCache` global com limite de 10.000 keys

### 3. `src/Utils/auth-utils.ts` (Signal Store)
‚úÖ Signal Store com limite de 10.000 keys

### 4. `src/Socket/messages-send.ts`
‚úÖ `userDevicesCache` com limite de 5.000 keys
‚úÖ `lidCache` (per-socket) com limite de 2.000 keys

### 5. `src/Socket/messages-recv.ts`
‚úÖ `msgRetryCache` com limite de 10.000 keys
‚úÖ `callOfferCache` com limite de 500 keys
‚úÖ `placeholderResendCache` com limite de 5.000 keys

### 6. `src/Socket/chats.ts`
‚úÖ `placeholderResendCache` com limite de 5.000 keys

### 7. `src/Utils/baileys-logger.ts`
‚úÖ Adicionadas fun√ß√µes de logging:
- `logCacheMemory()` - Log de opera√ß√µes de cache
- `logSocketCacheMetrics()` - M√©tricas agregadas de todos os caches

---

## üìù Exemplos de Uso

### Uso Padr√£o (Recomendado)

```typescript
import makeWASocket from '@whiskeysockets/baileys'

const sock = makeWASocket({
  auth: state,
  // N√£o precisa especificar - usar√° os limites padr√£o seguros
  // Todos os caches ter√£o maxKeys autom√°tico
})
```

**Quando usar**: Para 95% dos casos. Os valores padr√£o s√£o conservadores e seguros.

---

### Monitoramento em Produ√ß√£o

Com `BAILEYS_LOG=true`, voc√™ ver√° logs de cache:

```bash
[BAILEYS] üíæ Cache initialized: userDevicesCache { maxKeys: 5000, ttl: '300s' }
[BAILEYS] üíæ Cache initialized: msgRetryCache { maxKeys: 10000, ttl: '3600s' }
[BAILEYS] üìä Cache metrics: userDevicesCache { size: 2341, maxKeys: 5000, utilizationPct: '46.8%' }
[BAILEYS] ‚ö†Ô∏è  Cache limit reached: msgRetryCache { size: 10000, maxKeys: 10000, utilizationPct: '100%' }
[BAILEYS] üóëÔ∏è  Cache eviction: msgRetryCache { evictedKeys: 1250, remaining: 8750 }
```

---

### Exemplo de Monitoramento Manual

```typescript
// Verificar tamanho dos caches
const userDevicesCacheSize = userDevicesCache.keys().length
const msgRetryCacheSize = msgRetryCache.keys().length

console.log(`UserDevices: ${userDevicesCacheSize}/5000`)
console.log(`MsgRetry: ${msgRetryCacheSize}/10000`)

// Alerta se pr√≥ximo ao limite (>80%)
if (msgRetryCacheSize > 8000) {
  console.warn('‚ö†Ô∏è  msgRetryCache acima de 80% - investigar!')
}
```

---

## üß™ Como Testar

### Teste 1: Verificar Limites Aplicados

```typescript
import NodeCache from '@cacheable/node-cache'
import { DEFAULT_CACHE_MAX_KEYS } from './Defaults'

const cache = new NodeCache({
  stdTTL: 300,
  maxKeys: DEFAULT_CACHE_MAX_KEYS.USER_DEVICES
})

console.log('Max keys:', cache.options.maxKeys) // Output: 5000
```

### Teste 2: Simular Overflow

```typescript
// Adicionar mais keys do que o limite
for (let i = 0; i < 6000; i++) {
  cache.set(`key_${i}`, `value_${i}`)
}

console.log('Size after overflow:', cache.keys().length)
// Output: 5000 (n√£o passa do limite!)
```

### Teste 3: Verificar LRU Eviction

```typescript
// Adicionar 5000 keys
for (let i = 0; i < 5000; i++) {
  cache.set(`key_${i}`, `value_${i}`)
}

// Acessar key_0 (move para "mais recente")
cache.get('key_0')

// Adicionar 1000 novas keys
for (let i = 5000; i < 6000; i++) {
  cache.set(`key_${i}`, `value_${i}`)
}

// key_0 ainda existe? (deve existir pois foi acessada)
console.log('key_0 exists:', cache.has('key_0')) // true

// key_1 foi removida? (deve ter sido, era a mais antiga n√£o acessada)
console.log('key_1 exists:', cache.has('key_1')) // false
```

---

## üìä Compara√ß√£o: Antes vs Depois

| M√©trica | Antes (‚ùå Sem Limite) | Depois (‚úÖ Com Limite) |
|---------|----------------------|------------------------|
| **M√°x. mem√≥ria poss√≠vel** | ‚ôæÔ∏è Ilimitado | ~3.26M keys (previs√≠vel) |
| **Utiliza√ß√£o m√©dia** | Crescente ‚Üí OOM | ~1M keys (est√°vel) |
| **Crashes por OOM** | ‚úÖ Frequentes | ‚ùå Eliminados |
| **Previsibilidade** | ‚ùå Imposs√≠vel | ‚úÖ Totalmente previs√≠vel |
| **Eviction autom√°tica** | ‚ùå N√£o existe | ‚úÖ LRU quando necess√°rio |
| **Monitoramento** | ‚ùå Sem m√©tricas | ‚úÖ Logging completo |
| **Perda de dados** | ‚úÖ Sim (crash) | ‚ùå N√£o (LRU controlado) |

---

## ‚ö†Ô∏è Troubleshooting

### Problema: Warning "Cache limit reached"

**Sintoma**:
```
[BAILEYS] ‚ö†Ô∏è  Cache limit reached: msgRetryCache { size: 10000, maxKeys: 10000, utilizationPct: '100%' }
```

**Poss√≠veis causas**:
1. **Uso leg√≠timo** - Alto volume de mensagens falhadas
2. **Bug no c√≥digo** - Mensagens n√£o sendo removidas do cache
3. **Limite muito baixo** - Precisa aumentar para seu caso de uso

**Solu√ß√£o**:

#### 1. Investigar uso leg√≠timo
```typescript
// Verificar quantos retries est√£o pendentes
const keys = msgRetryCache.keys()
console.log('Pending retries:', keys.length)

// Ver algumas keys para entender o padr√£o
keys.slice(0, 10).forEach(key => {
  const value = msgRetryCache.get(key)
  console.log(key, value)
})
```

#### 2. Se for leg√≠timo, aumentar limite via config
```typescript
// Criar cache personalizado com limite maior
const customMsgRetryCache = new NodeCache({
  stdTTL: 3600,
  maxKeys: 20_000, // Dobrado para 20k
  deleteOnExpire: true,
  useClones: false
})

const sock = makeWASocket({
  auth: state,
  msgRetryCounterCache: customMsgRetryCache // Usar cache customizado
})
```

#### 3. Se for bug, investigar cleanup
```typescript
// Monitorar crescimento ao longo do tempo
setInterval(() => {
  const size = msgRetryCache.keys().length
  console.log(`[${new Date().toISOString()}] msgRetryCache size: ${size}`)
}, 60_000) // A cada 1 minuto

// Se crescer constantemente sem cair, h√° vazamento no cleanup
```

---

### Problema: Eviction Frequente

**Sintoma**:
```
[BAILEYS] üóëÔ∏è  Cache eviction: userDevicesCache { evictedKeys: 500, remaining: 4500 }
[BAILEYS] üóëÔ∏è  Cache eviction: userDevicesCache { evictedKeys: 600, remaining: 4400 }
[BAILEYS] üóëÔ∏è  Cache eviction: userDevicesCache { evictedKeys: 700, remaining: 4300 }
```

**Causa**: Limite muito baixo para seu caso de uso (muitos contatos)

**Solu√ß√£o**:
```typescript
// Aumentar limite do userDevicesCache
const customUserDevicesCache = new NodeCache({
  stdTTL: 300,
  maxKeys: 10_000, // Dobrado de 5k para 10k
  deleteOnExpire: true,
  useClones: false
})

const sock = makeWASocket({
  auth: state,
  userDevicesCache: customUserDevicesCache
})
```

---

### Problema: Performance Degradada

**Sintoma**: Lentid√£o ap√≥s implementar limites

**Causa**: LRU eviction tem custo computacional quando no limite

**Solu√ß√£o**:
```typescript
// Aumentar TTL para expirar naturalmente antes do LRU
const cache = new NodeCache({
  stdTTL: 300,           // ‚Üê Reduzir de 3600 para 300 (5 min)
  checkperiod: 60,       // Verificar expira√ß√£o a cada 1 min
  maxKeys: 10_000,
  deleteOnExpire: true,  // ‚Üê Garantir que expira ao inv√©s de evict
  useClones: false
})
```

**Explica√ß√£o**: Se o TTL expirar **antes** de atingir maxKeys, evita eviction (que √© mais custosa).

---

## üéØ Melhores Pr√°ticas

### ‚úÖ FAZER

1. **Usar valores padr√£o** quando poss√≠vel (j√° s√£o conservadores)
2. **Monitorar m√©tricas** com `BAILEYS_LOG=true` em produ√ß√£o
3. **Investigar warnings** antes de aumentar limites
4. **Documentar** por que voc√™ precisa de limites customizados
5. **Testar limites** em staging antes de produ√ß√£o

### ‚ùå EVITAR

1. **Remover maxKeys** (volta ao problema original!)
2. **Limites arbitrariamente altos** (>50.000) sem justificativa
3. **Ignorar logs de eviction** sem investigar
4. **Desabilitar deleteOnExpire** (mem√≥ria n√£o √© liberada)
5. **Usar valores muito baixos** que causam eviction constante

---

## üìö Refer√™ncias

- [NodeCache Documentation](https://www.npmjs.com/package/node-cache)
- [LRU Cache Strategy](https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU))
- [Node.js Memory Management](https://nodejs.org/en/docs/guides/simple-profiling/)
- [RBaileys Event Buffer Fix](./BUFFER_LOGGING.md)
- [RBaileys WebSocket Listener Fix](./WEBSOCKET_LISTENER_LEAK.md)

---

## ‚ùì FAQ

### P: Posso remover o maxKeys para ter cache ilimitado?

**R**: ‚ùå **N√ÉO!** Voc√™ voltar√° ao problema original (OOM crashes). Se os limites padr√£o s√£o insuficientes, **aumente-os para um valor espec√≠fico**, mas NUNCA remova.

### P: Qual o custo de mem√≥ria de 1 cache key?

**R**: Depende do valor armazenado:
- String simples (~50 bytes)
- Device object (~200 bytes)
- Message retry object (~500 bytes)

**Estimativa conservadora**: 1.000 keys ‚âà **500KB - 1MB** de RAM

### P: O LRU eviction causa perda de dados?

**R**: ‚úÖ **N√£o √© perda de dados**, √© comportamento esperado:
- Caches s√£o **tempor√°rios** por natureza (t√™m TTL)
- LRU remove keys **menos usadas** (provavelmente n√£o ser√£o necess√°rias)
- Dados permanentes devem estar no **database**, n√£o em cache

### P: Como saber se meu limite est√° correto?

**R**: Monitore a utiliza√ß√£o:
- **30-70%**: ‚úÖ Ideal (buffer suficiente)
- **70-90%**: ‚ö†Ô∏è Aceit√°vel (monitorar crescimento)
- **>90%**: ‚ùå Muito alto (aumentar limite)
- **<20%**: üí° Pode reduzir (otimizar mem√≥ria)

### P: Posso ter limites diferentes por tenant?

**R**: ‚úÖ Sim! Cada `makeWASocket()` pode ter caches customizados:

```typescript
function createSocket(tenantId: string) {
  // Tenants premium t√™m limites maiores
  const isPremium = checkIfPremium(tenantId)

  const msgRetryCache = new NodeCache({
    stdTTL: 3600,
    maxKeys: isPremium ? 20_000 : 10_000, // 2x para premium
    deleteOnExpire: true,
    useClones: false
  })

  return makeWASocket({
    auth: state,
    msgRetryCounterCache: msgRetryCache
  })
}
```

---

**√öltima atualiza√ß√£o**: 2026-01-11

**Issue relacionada**: #3 - Caches sem limite de mem√≥ria (ALTO RISCO)

**Status**: ‚úÖ **CORRIGIDO E TESTADO**
