# üîß Troubleshooting - Pain√©is do Grafana Sem Dados

## Problema: Pain√©is 111, 112, 113 N√£o Mostram Dados

Os pain√©is de **Buffers Destru√≠dos** foram implementados corretamente, mas podem n√£o mostrar dados imediatamente. Aqui est√° o guia completo de troubleshooting.

---

## ‚úÖ Verifica√ß√µes Necess√°rias

### 1. Aplica√ß√£o Foi Reiniciada?

As novas m√©tricas do Prometheus s√≥ s√£o registradas quando a aplica√ß√£o **inicia**. Se voc√™ fez deploy do c√≥digo mas n√£o reiniciou:

```bash
# PM2
pm2 restart zpro-backend
pm2 logs zpro-backend --lines 50

# Ou diretamente
npm start
```

**Procure nos logs:**
```
‚úÖ Prometheus metrics server started on port 3000
```

---

### 2. Prometheus Est√° Habilitado?

Verifique a configura√ß√£o do Prometheus no arquivo de configura√ß√£o:

```typescript
// config/prometheus.ts ou similar
{
  enabled: true,  // ‚Üê DEVE SER true
  port: 3000,     // Porta do endpoint /metrics
  prefix: 'zpro_baileys_'
}
```

---

### 3. Endpoint /metrics Est√° Acess√≠vel?

Execute o script de teste:

```bash
cd /path/to/RBaileys
bash scripts/test-buffer-metrics.sh
```

Ou manualmente:

```bash
# Ajuste a porta conforme sua configura√ß√£o
curl http://localhost:3000/metrics | grep buffer_destroyed
curl http://localhost:3000/metrics | grep buffer_final_flush
curl http://localhost:3000/metrics | grep buffer_active
```

**Sa√≠da esperada:**
```prometheus
# HELP zpro_baileys_buffer_destroyed_total Total number of event buffers destroyed (prevents orphaned buffers)
# TYPE zpro_baileys_buffer_destroyed_total counter
zpro_baileys_buffer_destroyed_total{reason="socket_close",had_pending_flush="false"} 0

# HELP zpro_baileys_buffer_final_flush_total Total number of final flushes performed during buffer destruction
# TYPE zpro_baileys_buffer_final_flush_total counter
zpro_baileys_buffer_final_flush_total{items_count="empty"} 0

# HELP zpro_baileys_buffer_active_count Number of currently active event buffers
# TYPE zpro_baileys_buffer_active_count gauge
zpro_baileys_buffer_active_count 2
```

---

### 4. M√©tricas Est√£o em 0 (Zero)?

**Isso √© NORMAL!**

As m√©tricas s√£o **Counters** que come√ßam em `0` e s√≥ incrementam quando eventos acontecem:

- `buffer_destroyed_total` ‚Üí incrementa quando um socket desconecta
- `buffer_final_flush_total` ‚Üí incrementa quando h√° flush final durante destrui√ß√£o
- `buffer_active_count` ‚Üí mostra n√∫mero atual de buffers ativos

**Para gerar dados de teste:**
1. Conecte um n√∫mero de WhatsApp na aplica√ß√£o
2. Desconecte o n√∫mero (fecha conex√£o)
3. O buffer ser√° destru√≠do e as m√©tricas incrementam

---

### 5. Prometheus Est√° Coletando as M√©tricas?

Verifique se o Prometheus Server est√° configurado para coletar m√©tricas da sua aplica√ß√£o:

```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'zpro-backend'
    static_configs:
      - targets: ['localhost:3000']  # Ajuste para seu host:porta
```

**Teste no Prometheus UI:**
1. Acesse `http://localhost:9090` (ou sua URL do Prometheus)
2. Digite na query: `zpro_baileys_buffer_destroyed_total`
3. Clique em "Execute"

Se n√£o aparecer nada, o Prometheus n√£o est√° coletando.

---

### 6. Datasource do Grafana Est√° Correto?

Os pain√©is usam o datasource UID `efa2xes2233swf`. Verifique se existe:

**No Grafana:**
1. V√° em Configuration ‚Üí Data Sources
2. Procure pelo datasource do Prometheus
3. Copie o **UID** correto
4. Se for diferente de `efa2xes2233swf`, voc√™ precisa atualizar o dashboard

**Atualizar UID no dashboard:**
```bash
# Edite manualmente
nano docs/improvements/grafana/Dashboard\ Baileys.json

# Ou use sed
sed -i 's/efa2xes2233swf/SEU_UID_AQUI/g' docs/improvements/grafana/Dashboard\ Baileys.json
```

---

## üêõ Debug Avan√ßado

### Verificar Logs da Aplica√ß√£o

```bash
# PM2
pm2 logs zpro-backend | grep "destroying event buffer"

# Diretamente
tail -f logs/app.log | grep "buffer"
```

**Procure por:**
```json
{
  "level": "info",
  "msg": "destroying event buffer",
  "buffersInProgress": 1,
  "itemsBuffered": 5,
  "flushCount": 3
}
```

### Verificar Se C√≥digo Compilado Est√° Atualizado

```bash
# Verificar data dos arquivos compilados
ls -lah lib/Utils/event-buffer.js
ls -lah lib/Utils/prometheus-metrics.js

# Procurar pelas chamadas das m√©tricas
grep -n "recordBufferDestroyed" lib/Utils/event-buffer.js
grep -n "recordBufferFinalFlush" lib/Utils/event-buffer.js
```

Se n√£o encontrar as chamadas, recompile:
```bash
npm run build
# ou
npx tsc
```

---

## üìä Queries de Teste no Grafana

Voc√™ pode testar as queries diretamente no Grafana Explore:

1. V√° em **Explore** no menu lateral
2. Selecione o datasource do Prometheus
3. Cole estas queries:

```promql
# Total de buffers destru√≠dos
zpro_baileys_buffer_destroyed_total

# Taxa de destrui√ß√£o por minuto
rate(zpro_baileys_buffer_destroyed_total[5m]) * 60

# Flush final durante destrui√ß√£o
zpro_baileys_buffer_final_flush_total

# Buffers ativos agora
zpro_baileys_buffer_active_count
```

---

## üÜò Ainda N√£o Funciona?

Se depois de todas essas verifica√ß√µes ainda n√£o funcionar:

### Checklist Final:

- [ ] Aplica√ß√£o foi reiniciada ap√≥s deploy
- [ ] Prometheus est√° habilitado na config
- [ ] Endpoint /metrics retorna as novas m√©tricas
- [ ] Prometheus Server est√° coletando (scraping)
- [ ] Datasource UID est√° correto no dashboard
- [ ] J√° houve pelo menos uma desconex√£o de WhatsApp para gerar dados

### Informa√ß√µes para Suporte:

Cole essas informa√ß√µes para debug:

```bash
# 1. Vers√£o do c√≥digo
git log -1 --oneline

# 2. Status das m√©tricas
curl http://localhost:3000/metrics | grep buffer

# 3. Configura√ß√£o do Prometheus
cat config/prometheus.ts  # ou onde estiver a config

# 4. Logs recentes
pm2 logs zpro-backend --lines 50 | grep buffer
```

---

## ‚úÖ Funcionou!

Quando funcionar, voc√™ dever√° ver:

- **Panel 111**: N√∫mero total de buffers destru√≠dos (cresce a cada desconex√£o)
- **Panel 112**: Gr√°fico de taxa de destrui√ß√£o por minuto
- **Panel 113**: Total de flushes finais executados

Essas m√©tricas ajudam a monitorar:
- Desconex√µes frequentes (problema de rede?)
- Buffers √≥rf√£os sendo limpos
- Perda de dados evitada pelo flush final
